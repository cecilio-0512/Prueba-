####################################################Paqueter铆as a usar ##########################

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt


# --- Leer archivo Excel ---
ecomm = pd.read_excel(
    "E Commerce Dataset.xlsx",
    sheet_name="E Comm"
)


#Transformar a variables de tipo categ贸rico variables que hayan sido guardadas en otro formato
cat_force = [
    "PreferredLoginDevice",      # nominal
    "PreferredPaymentMode",      # nominal
    "Gender",                    # binaria
    "MaritalStatus",             # nominal
    "Complain",                  # binaria (0/1)
    "CityTier",                  # ordinal/categ贸rica; aqu铆 la tratamos como nominal para no asumir linealidad
    "PreferedOrderCat"           # nominal (estaba impl铆cita)
]

# Asegurar existencia antes de castear (por si hay variaciones en el archivo)
cat_present = [c for c in cat_force if c in ecomm.columns]
ecomm[cat_present] = ecomm[cat_present].apply(lambda s: s.astype("category"))


# --- Diccionario  -> descripci贸n ---
desc_es = {
    "CustomerID": "ID 煤nico del cliente",
    "Churn": "Indicador de fuga (1 = se fue, 0 = se qued贸)",
    "Tenure": "Antig眉edad del cliente (p. ej., meses)",
    "PreferredLoginDevice": "Dispositivo preferido para iniciar sesi贸n",
    "CityTier": "Nivel de la ciudad (1 = grande, etc.)",
    "WarehouseToHome": "Distancia almac茅n-hogar (p. ej., km)",
    "PreferredPaymentMode": "M茅todo de pago preferido", 
    "Gender": "G茅nero del cliente",
    "HourSpendOnApp": "Horas de uso de la app",
    "NumberOfDeviceRegistered": "N煤mero de dispositivos registrados",
    "PreferedOrderCat": "Categor铆a de productos m谩s ordenada",
    "SatisfactionScore": "Calificaci贸n de satisfacci贸n (escala corta)",
    "MaritalStatus": "Estado civil",
    "NumberOfAddress": "N煤mero de direcciones registradas",
    "Complain": "驴Ha hecho queja? (1 = S铆, 0 = No)",
    "OrderAmountHikeFromlastYear": "Incremento % del gasto vs. a帽o previo",
    "CouponUsed": "Cantidad de cupones usados",
    "OrderCount": "N煤mero de 贸rdenes realizadas",
    "DaySinceLastOrder": "D铆as desde la 煤ltima orden",
    "CashbackAmount": "Monto de cashback recibido",
}

# --- Crear DataFrame con la info ---
traduccion_variables = (
    pd.DataFrame({"variable": ecomm.columns})
    .assign(dtype=lambda df: df["variable"].map(dict(zip(ecomm.columns, ecomm.dtypes.astype(str)))))
    .assign(descripcion=lambda df: df["variable"].map(desc_es).fillna(""))
    .loc[:, ["variable", "dtype", "descripcion"]]
    .sort_values("variable")
    .reset_index(drop=True)
)

st.title(" T茅cnicas de Machine Learning para la Prevenci贸n del Retiro de Clientes")

st.markdown("""
Este reporte presenta la aplicaci贸n de **t茅cnicas de Machine Learning** para el an谩lisis del comportamiento de los clientes de **MarMen**, 
utilizando la informaci贸n disponible en la base de datos de *E-Commerce*.  
El objetivo principal es **identificar y clasificar a los clientes propensos a retirarse (variable *churn*)**, 
para dise帽ar estrategias de retenci贸n e incentivos que reduzcan la fuga.  

###  Flujo del An谩lisis
1. **Exploraci贸n inicial de datos** y construcci贸n de un **diccionario de variables**, con el fin de comprender la estructura y relevancia de la informaci贸n disponible.  
2. **Entrenamiento de un modelo de clasificaci贸n** (Regresi贸n Log铆stica con regularizaci贸n L1), orientado a identificar las variables con mayor impacto en la predicci贸n de la fuga.  
3. **Evaluaci贸n de distintos umbrales de decisi贸n**, comparando m茅tricas como:  
   - *Recall*  
   - *Precisi贸n*  
   - *Balanced Accuracy*  
   - *Accuracy*  
   para analizar el desempe帽o en diferentes escenarios de negocio.  
4. **Conclusiones y recomendaciones estrat茅gicas**, basadas en los resultados obtenidos y en los objetivos espec铆ficos del cliente.  

---
""")

# --- Mostrar tabla ---
st.subheader(" Traducci贸n variables ")
st.dataframe(traduccion_variables, use_container_width=True)

# --- (Opcional) bot贸n de descarga ---
csv_dict = traduccion_variables.to_csv(index=False).encode("utf-8")
st.download_button(
    label=" Descargar diccionario (CSV)",
    data=csv_dict,
    file_name="diccionario_variables.csv",
    mime="text/csv"
)

# --- Distribuci贸n de la variable objetivo (Churn) ---


# Calcular proporciones
churn_counts = ecomm["Churn"].value_counts()
churn_labels = ["Se queda (0)", "Se retira (1)"]

# Gr谩fica de pastel con fondo transparente y texto blanco
fig, ax = plt.subplots(facecolor="none")  # fondo transparente
wedges, texts, autotexts = ax.pie(
    churn_counts,
    labels=churn_labels,
    autopct="%1.1f%%",
    startangle=90,
    counterclock=False,
    textprops={"color": "white"}  # texto blanco
)

st.subheader(" Vista previa de la base de datos E-Commerce")
st.dataframe(ecomm.head(10)) 


# Ajustar tambi茅n el t铆tulo
ax.set_title("Distribuci贸n respuesta de variable churn", color="white")

st.pyplot(fig, transparent=True)


st.markdown("""
Se observa que la distribuci贸n de la respuesta de la variable *Churn* est谩 desbalanceada: 83% de clientes se quedan y 17% se retiran. Este desbalance se toma en cuenta al momento de analalizar el resultado de las predicciones """)



# --- Tabla resumen de valores nulos ---
n_obs = len(ecomm)
resumen_inicial = (
    pd.DataFrame({
        "variable": ecomm.columns,
        "dtype": ecomm.dtypes.astype(str).values,
        "n_missing": ecomm.isnull().sum().values
    })
    .assign(pct_missing=lambda df: (df["n_missing"] / n_obs * 100).round(2))
    .sort_values(["n_missing", "variable"], ascending=[False, True])
    .reset_index(drop=True)
)


st.subheader(" Resumen inicial de la base de datos")
st.dataframe(resumen_inicial, use_container_width=True)


st.markdown("""Existen variables 7 con presencia de valores NA (aproximadamente 5% de valores faltantes del total de observaciones), dado este porcentaje relativamente menor de valores NA se procede a hacer la imputaci贸n por media y moda dependiendo del tipo de variable durante el proceso del entrenamiento del modelo. """)



st.markdown("###  Modelo estad铆stico: Regresi贸n Log铆stica")

# --- Explicaci贸n formal ---
st.markdown("""
En todo modelo de regresi贸n, el objetivo es **optimizar una funci贸n objetivo** 
para encontrar los par谩metros que mejor explican los datos.  

- En la **regresi贸n lineal**, la funci贸n objetivo t铆pica es minimizar la **suma de los residuos al cuadrado**.""") 
st.latex(r"\sum_{i=1}^{n} \left(Y_i - (\beta_0 + \beta_1 X_i)\right)^2")


# Ilustraci贸n: regresi贸n lineal simple
st.image(
    "maxresdefault.png",   
    caption="Regresi贸n lineal simple: l铆nea de mejor ajuste minimizando la suma de residuos al cuadrado.",
    use_container_width=True

)
             
st.markdown("""- En la **regresi贸n log铆stica**, como la variable de inter茅s es **binaria (0/1)**, 
no tiene sentido usar residuos al cuadrado. En su lugar se utiliza la **log-verosimilitud**, 
que mide qu茅 tan probable es que el modelo genere los datos observados.
""")

st.markdown("La forma del modelo log铆stico es:")

st.latex(r"""
P(Y=1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p)}}
""")

st.markdown("""

En este proyecto utilizamos la **regresi贸n log铆stica con regularizaci贸n L1 (Lasso)**.  
En este caso, la funci贸n objetivo incorpora una penalizaci贸n adicional para controlar la complejidad del modelo:

""")

st.latex(r"""
\mathcal{L}_{L1}(\beta) = - \sum_{i=1}^n \Big[ y_i \log(p_i) + (1-y_i)\log(1-p_i) \Big] 
\;+\; \lambda \sum_{j=1}^p |\beta_j|
""")

st.markdown("""
donde """) 

st.latex(r""" \lambda """)  

st.markdown(""" Es conocido como un hiperpar谩metro que controla la fuerza de la penalizaci贸n. El efecto de esta penalizaci贸n es que algunos coeficientes del modelo se reduzcan a **cero**, 
lo cual equivale a una **selecci贸n autom谩tica de variables**.

As铆, la regresi贸n log铆stica regularizada no solo estima probabilidades, 
sino que tambi茅n ayuda a identificar las caracter铆sticas m谩s relevantes en la predicci贸n del churn. """)
            
            

st.markdown("### 锔 Entrenamiento del modelo")

st.image(
    "entrenamiento.png",   
    caption="Regresi贸n lineal simple: l铆nea de mejor ajuste minimizando la suma de residuos al cuadrado.",
    use_container_width=True

)

st.markdown("###  Resultados")



